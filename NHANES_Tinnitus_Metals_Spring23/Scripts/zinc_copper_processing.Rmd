---
title: "Zinc"
author: "Valerie Ingalls"
date: "2022-10-28"
output: html_document
---

```{r setup, include=FALSE}
library(foreign)
library(tidyverse)
library(bestNormalize)
library(ggplot2)
#install.packages("moments")
```

First, we have to read all of our data files into R. There are 5 different files for each cycle.

```{r import}
demo11 <- read.xport("../Data/RAW_data/DEMO_G.XPT")
auq11 <- read.xport("../Data/RAW_data/AUQ_G.XPT")
zinc11 <- read.xport("../Data/RAW_data/CUSEZN_G.XPT")
fast11 <- read.xport("../Data/RAW_data/FASTQX_G.XPT")

demo15 <- read.xport("../Data/RAW_data/DEMO_I.XPT")
auq15 <- read.xport("../Data/RAW_data/AUQ_I.XPT")
zinc15 <- read.xport("../Data/RAW_data/CUSEZN_I.XPT")
fast15 <- read.xport("../Data/RAW_data/FASTQX_I.XPT")
```

We're going to process this data all together, so we can combine our 10 dataframes into 1 here at the start. Sheets don't have matching columns within cycles so we use full join to get all of our data. Final join could be whatever variety.

```{r join}
zinc_data15 <- full_join(demo15, auq15) %>%
  full_join(zinc15) %>%
  full_join(fast15)

zinc_data11 <- full_join(demo11, auq11) %>%
  full_join(zinc11) %>%
  full_join(fast11)

zinc_all <- full_join(zinc_data11, zinc_data15)
```

First step in wrangling is to select only the columns that we need for the ensuing steps. This will makes a few later steps run a bit faster than if we had all columns remaining.

```{r select}
zinc_trimmed <- zinc_all %>%
  select(c(SEQN, SDDSRVYR, RIAGENDR, RIDAGEYR, RIDRETH3, WTINT2YR, WTMEC2YR, SDMVPSU, SDMVSTRA, AUQ191, AUQ280, AUQ250, AUQ260, AUQ100, AUQ330, AUQ331, AUQ370, AUQ300, WTSA2YR, LBXSCU, LBXSZN, PHDSESN))
```

Here we 
1. rename our variables to be legible 
2. refactor existing variables 
3. compute some new variables 
4. remove unwated values from the data (7 and 9 answer codes are implicit NAs, for example) 
5. trim off any remaining unwanted variables 


```{r cleaning}
# rename
zinc_refactor <- zinc_trimmed %>%
  rename("cycle" = "SDDSRVYR",
         "sex" = "RIAGENDR",
         "age_yrs" = "RIDAGEYR",
         "ethnicity" = "RIDRETH3",
         "interview_weight" = "WTINT2YR",
         "examination_weight" = "WTMEC2YR",
         "subsample_weight" = "WTSA2YR",
         "psu" = "SDMVPSU",
         "stratum" = "SDMVSTRA",
         "tinnitus_any" = AUQ191,
         "tinnitus_severity" = AUQ280,
         "tinnitus_duration" = AUQ250,
         "noise_only" = AUQ260,
         "speech_in_noise" = AUQ100,
         "copper" = LBXSCU,
         "zinc" = LBXSZN,
         "session" = PHDSESN
  ) %>%
# refactor, compute, combine for various variables
  mutate(
         "ethnicity" = if_else(`ethnicity` == 3, 1, 2), # 1 = white, 2 is non white/Hispanic. Follows other tin. studies
         "combined_subsample_weight" = subsample_weight/2, # proper method for weight when using multiple cycles. Take weight, divide by number of cycles
         across(c(tinnitus_any, tinnitus_severity, tinnitus_duration, noise_only, sex, speech_in_noise),  ~na_if(., 7)), # na coded null values
         across(c(tinnitus_any, tinnitus_severity, tinnitus_duration, noise_only, sex, speech_in_noise),  ~na_if(., 9)),
         "problematic" = if_else(tinnitus_severity == 1, 0, 1), # no problem vs some problem
         "acute_chronic" = if_else(tinnitus_duration >= 3, 1, 0), # tinnitus lasting at least a year vs not
         "tinnitus_type" = if_else(tinnitus_any == 2, 3, 1),
         "tinnitus_type" = if_else(!is.na(problematic) & problematic == 0, 2, 
                                   if_else(!is.na(acute_chronic) & acute_chronic == 0, 2,
                                           if_else(!is.na(noise_only) & noise_only == 1, 2, tinnitus_type))),
# 1: bothersome chronic, 2: not bothersome or not chronic or noise-exposure only (other tinnitus), 3: no tinnitus
         "cycle" = if_else(cycle == 7, "2011-2012", "2015-2016"), # changing cycle code to a year for clarity
         "zinc_cutoff" = if_else(age_yrs >= 10, # using standards to control zinc deficiency cutoff based on known factors. no such info found on copper, so that cutoff is less controlled
                                     if_else(sex == 1, if_else(session == 1, 74, 61), 
                                     if_else(session == 1, 70, 59)),
                                     if_else(session == 1, 65, 57)),
         "zinc_deficiency" = if_else(`zinc` < zinc_cutoff, 1, 0), # 0 is no deficiency
         "copper_deficiency" = if_else(`copper` < 63.7, 1, 0), # 63.7 is the standard medical threshold.
         "tinnitus_any" = if_else(tinnitus_any == 1, 1, 0)
  ) %>%
# remove remaining unwanted variables
  select(c(SEQN, cycle, sex, age_yrs, ethnicity, combined_subsample_weight, psu, stratum, tinnitus_any, tinnitus_type, zinc, copper, speech_in_noise, zinc_deficiency, copper_deficiency))
    
```




```{r subset}
# file without NA's for easier use with SPSS; no purpose here
#zinc_SPSS <- zinc_refactor %>%
#    replace(is.na(.), "")


# removing rows with incomplete data; partially for cleanliness, partially for better functioning with later analyses
zinc_subset <- zinc_refactor %>%
  filter(!is.na(zinc)) %>%
  filter(!is.na(copper)) %>%
  filter(!is.na(speech_in_noise)) %>%
  filter(!is.na(tinnitus_type))
```


In preliminary analyses, it was noted that there is skew in the values of serum copper and zinc. Therefore, we will transform these variables in order to try and normalize our response variables for statistical analyses.

The bestNormalize() function runs a series of transformations and indicates the one with the least-skewed result. We will use this to determine the best transformation for our data.
```{r normalizationZinc}

zinc_norm_result <- bestNormalize(zinc_subset$zinc)
zinc_norm_result
#sqrt transform selected. we will perform this manually do avoid unwanted standardization.=

normed_zinc <- sqrt(zinc_subset$zinc)


#final check for improvement
moments::skewness(zinc_subset$zinc)
moments::skewness(normed_zinc)


```
```{r normalizationCopper}
copper_norm_result <- bestNormalize(zinc_subset$copper)
copper_norm_result
#Yeo-Johnson transformation selected. Again will be performed manually to avoid standardization from the bestNormalize function
# selected lambda value of -0.5191
chosenLambda <- copper_norm_result$chosen_transform$lambda
normed_copper <- (((zinc_subset$copper + 1)^chosenLambda - 1)/chosenLambda)


#final check for improvement
moments::skewness(zinc_subset$copper)
moments::skewness(normed_copper)
```

Note that the methods used by the bestNormalize() function are not 100% consistent. Due to this, if multiple transformations result in extremely similar skewness values, one run of the function may favor one transformation, and the next run of it may favor a different one. As this is the case for our zinc measurement, we have elected to use the simplest transformation of those that the function alternately favors: square root.  


In both cases of zinc and copper we can see that these methods have reduced the skewness of the distribution, so we will attempt analyses using the transformed zinc and copper distributions. Appending the vectors of transformed values to our final data frame.

```{r appendNorm}
zinc_final <- zinc_subset %>%
  mutate("normedZinc" = normed_zinc,
         "normedCopper" = normed_copper)
```




```{r write}
# final output csv that we're going to read into our analysis rmd
write.csv(zinc_final, file = "../Data/processed_metal_data.csv")
```
